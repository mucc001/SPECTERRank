{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e83833b2-26e1-4651-b43c-132b8f6f916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6184087b-52e8-4c63-99a5-33c0ce270b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_meta = pd.read_json('meta.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18b9d7ad-de62-4446-b078-171b309b1b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>references</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROBLEM STATEMENT\\nPelvic girdle pain (PGP) is...</td>\n",
       "      <td>[40572137, 3675075, 48815127]</td>\n",
       "      <td>[e7e7a7fc07f516fd39b4b0cb7ff3a2acfe837c1a, e87...</td>\n",
       "      <td>[420604a2d0161cd5b5d2df75dd6252f224c8b055, e78...</td>\n",
       "      <td>Pelvic Girdle Pain during or after Pregnancy: ...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1417926</td>\n",
       "      <td>0003aa77bdefc1c75f9d2ba732635c132fc0c863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Routers must perform packet classification at ...</td>\n",
       "      <td>[23633340, 1688025, 1746289]</td>\n",
       "      <td>[76d64770fc8f032d047b034650c666e2c731c87e, bfb...</td>\n",
       "      <td>[0e541308cc7c5ce8574bab03c090b6a0c5c6355b, 1a1...</td>\n",
       "      <td>Packet Classification Using Tuple Space Search</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>207574370</td>\n",
       "      <td>0007181efc556fd1fcda2642e9bd85dd0f0c32d6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The data of interest are assumed to be represe...</td>\n",
       "      <td>[1869497, 3143096, 1746676]</td>\n",
       "      <td>[f354b0103c4bc8cb14bed77a27f5f4ffe580efdb, 7bf...</td>\n",
       "      <td>[d68725804eadecf83d707d89e12c5132bf376187, 57b...</td>\n",
       "      <td>Bayesian Compressive Sensing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>206797074</td>\n",
       "      <td>000c009765a276d166fc67595e107a9bc44f230d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic image segmentation is an essential co...</td>\n",
       "      <td>[3408089, 36665147, 11983029, 1789756]</td>\n",
       "      <td>[c2c0fda9b4e2a12fd4069ab545e90ec4a197e66d, 1fa...</td>\n",
       "      <td>[981fef7155742608b8b6673f4a9566158b76cd67, 942...</td>\n",
       "      <td>Full-Resolution Residual Networks for Semantic...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1873339</td>\n",
       "      <td>000f90380d768a85e2316225854fc377c079b5c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We introduce the social study of bullying to t...</td>\n",
       "      <td>[1729642, 2610963, 1832364, 3009549]</td>\n",
       "      <td>[6618b4dbea9cc0a229e603c0326eac957c420ac4, 49b...</td>\n",
       "      <td>[639c1ec9edcbca7aa80ab56a52487def431aed5e, 899...</td>\n",
       "      <td>Learning from Bullying Traces in Social Media</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>9912528</td>\n",
       "      <td>00111610254bfb8ec16428501c2ca68dcf817474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  PROBLEM STATEMENT\\nPelvic girdle pain (PGP) is...   \n",
       "1  Routers must perform packet classification at ...   \n",
       "2  The data of interest are assumed to be represe...   \n",
       "3  Semantic image segmentation is an essential co...   \n",
       "4  We introduce the social study of bullying to t...   \n",
       "\n",
       "                                  authors  \\\n",
       "0           [40572137, 3675075, 48815127]   \n",
       "1            [23633340, 1688025, 1746289]   \n",
       "2             [1869497, 3143096, 1746676]   \n",
       "3  [3408089, 36665147, 11983029, 1789756]   \n",
       "4    [1729642, 2610963, 1832364, 3009549]   \n",
       "\n",
       "                                            cited_by  \\\n",
       "0  [e7e7a7fc07f516fd39b4b0cb7ff3a2acfe837c1a, e87...   \n",
       "1  [76d64770fc8f032d047b034650c666e2c731c87e, bfb...   \n",
       "2  [f354b0103c4bc8cb14bed77a27f5f4ffe580efdb, 7bf...   \n",
       "3  [c2c0fda9b4e2a12fd4069ab545e90ec4a197e66d, 1fa...   \n",
       "4  [6618b4dbea9cc0a229e603c0326eac957c420ac4, 49b...   \n",
       "\n",
       "                                          references  \\\n",
       "0  [420604a2d0161cd5b5d2df75dd6252f224c8b055, e78...   \n",
       "1  [0e541308cc7c5ce8574bab03c090b6a0c5c6355b, 1a1...   \n",
       "2  [d68725804eadecf83d707d89e12c5132bf376187, 57b...   \n",
       "3  [981fef7155742608b8b6673f4a9566158b76cd67, 942...   \n",
       "4  [639c1ec9edcbca7aa80ab56a52487def431aed5e, 899...   \n",
       "\n",
       "                                               title    year  corpus_id  \\\n",
       "0  Pelvic Girdle Pain during or after Pregnancy: ...  2013.0    1417926   \n",
       "1     Packet Classification Using Tuple Space Search  1999.0  207574370   \n",
       "2                       Bayesian Compressive Sensing  2008.0  206797074   \n",
       "3  Full-Resolution Residual Networks for Semantic...  2017.0    1873339   \n",
       "4      Learning from Bullying Traces in Social Media  2012.0    9912528   \n",
       "\n",
       "                                     doc_id  \n",
       "0  0003aa77bdefc1c75f9d2ba732635c132fc0c863  \n",
       "1  0007181efc556fd1fcda2642e9bd85dd0f0c32d6  \n",
       "2  000c009765a276d166fc67595e107a9bc44f230d  \n",
       "3  000f90380d768a85e2316225854fc377c079b5c4  \n",
       "4  00111610254bfb8ec16428501c2ca68dcf817474  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ba46f3-31d6-44d6-8d38-9ff2d0272291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': \"PROBLEM STATEMENT\\nPelvic girdle pain (PGP) is a common condition during or after pregnancy with pain and disability as most important symptoms. These symptoms have a wide range of clinical presentation. Most doctors perceive pregnancy related pelvic girdle pain (PPGP) as 'physiologic' or 'expected during pregnancy', where no treatment is needed. As such women with PPGP mostly experience little recognition. However, many scientific literature describes PPGP as being severe with considerable levels of pain and disability and socio-economic consequences in about 20% of the cases.\\n\\n\\nOBJECTIVES\\nWe aimed to (1) inform the gynecologist/obstetrician about the etiology, diagnosis, risk factors, and treatment options of PPGP and (2) to make a proposition for an adequate clinical care path.\\n\\n\\nMETHODS\\nA systematic search of electronic databases and a check of reference lists for recent researches about the diagnosis, etiology, risk factors and treatment of PPGP.\\n\\n\\nRESULTS\\nAdequate treatment is based on classification in subgroups according to the different etiologic factors. The various diagnostic tests can help to make a differentiation in the several pelvic girdle pain syndromes and possibly reveal the underlying biomechanical problem. This classification can guide appropriate multidimensional and multidisciplinary management. A proposal for a clinical care path starts with recognition of gynecologist and midwife for this disorder. Both care takers can make a preliminary diagnosis of PPGP and should refer to a physiatrist, who can make a definite diagnosis. Together with a physiotherapist, the latter can determine an individual tailored exercise program based on the influencing bio-psycho-social factors.\", 'authors': ['40572137', '3675075', '48815127'], 'cited_by': ['e7e7a7fc07f516fd39b4b0cb7ff3a2acfe837c1a', 'e87c5465ae8d9e22c237b8a1735ab5992466f1c4', 'c35d73aed8ccf2380988df0e7f33a16352c3250e', 'd6d34353052938630c216bb502958e0c5fa8151f', 'a3848ea423dd9d5ac2409df2444b63a323908191', '29552e98facc811dd37096f95fde28ab8c3a350f', '7814552e978d3ebda7abd56aaeff6d7f6567df93'], 'references': ['420604a2d0161cd5b5d2df75dd6252f224c8b055', 'e78149afc38dac0f78bad1b8020f24cf08dcb5f7', 'b613facdfc71d82c1a78b5b652b239aed9be42ff', 'c9c4cb05b9e69907544c59c7fe431860195c9f1c', '5b5a6f447e000fe70eadc505a746a9b2b396a401', '6e70287fc5b78938a78abaae9e4f3c7f7b343560', 'ee1bd624aa3df264a5b71f81528f8fe64d05471d', '0137dcff4d46e31f4bdcf1ce1a0ee2ba1f80abff', '58d712de2f8ed57ebd4697eb49c341c1fc113287', '5620994a1e6420d9119002a26e5792f6043b87f4'], 'title': 'Pelvic Girdle Pain during or after Pregnancy: a review of recent evidence and a clinical care path proposal', 'year': 2013, 'corpus_id': 1417926, 'doc_id': '0003aa77bdefc1c75f9d2ba732635c132fc0c863'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSONL file into a list\n",
    "with open('meta.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Print the list of dictionaries\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169cd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete corpus_id in doc to avoid Elasticsearch parsing error. \n",
    "# Some corpus_ids is the same as doc_ids, which makes them in different data type from other corpus_ids. \n",
    "# This may cause paring error during ElasticSearch indexing.\n",
    "for dictionary in data:\n",
    "    del(dictionary['corpus_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6da6f80b-1adc-40e8-8e7e-9d8c0e0d97d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'Jamie-Suns-MacBook-Pro.local', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'yGzXocvqRKafPLJDOdcQTg', 'version': {'number': '8.5.0', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'c94b4700cda13820dad5aa74fae6db185ca5c304', 'build_date': '2022-10-24T16:54:16.433628434Z', 'build_snapshot': False, 'lucene_version': '9.4.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff338a7f-ffd8-4652-908e-7f0ae43285b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total num of docs exceeds 140k, so it is more effective to index only the candidate docs. \n",
    "# es.indices.delete(index='scidoc_citation')\n",
    "# for doc in data:\n",
    "#     es.index(index=\"scidoc_citation\", \n",
    "#              id = doc['doc_id'], \n",
    "#              document = doc\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19f59f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 142009, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=\"scidoc_citation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d5a028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 8541, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=\"s2_doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336ce7ab-5768-44e3-a7f9-113efce3b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_prediction = pd.read_json('test_qrel.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb7fd4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>cand_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78495383450e02c5fe817e408726134b3084905d</td>\n",
       "      <td>632589828c8b9fca2c3a59e97451fde8fa7d188d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78495383450e02c5fe817e408726134b3084905d</td>\n",
       "      <td>86e87db2dab958f1bd5877dc7d5b8105d6e31e46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78495383450e02c5fe817e408726134b3084905d</td>\n",
       "      <td>2a047d8c4c2a4825e0f0305294e7da14f8de6fd3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78495383450e02c5fe817e408726134b3084905d</td>\n",
       "      <td>506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78495383450e02c5fe817e408726134b3084905d</td>\n",
       "      <td>51317b6082322a96b4570818b7a5ec8b2e330f2f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query_id  \\\n",
       "0  78495383450e02c5fe817e408726134b3084905d   \n",
       "1  78495383450e02c5fe817e408726134b3084905d   \n",
       "2  78495383450e02c5fe817e408726134b3084905d   \n",
       "3  78495383450e02c5fe817e408726134b3084905d   \n",
       "4  78495383450e02c5fe817e408726134b3084905d   \n",
       "\n",
       "                                    cand_id  score  \n",
       "0  632589828c8b9fca2c3a59e97451fde8fa7d188d      1  \n",
       "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46      1  \n",
       "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3      1  \n",
       "3  506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6      1  \n",
       "4  51317b6082322a96b4570818b7a5ec8b2e330f2f      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cd27595-162c-4169-b34c-ecc43f94a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_candidates(df):\n",
    "    positive_candidates = {}\n",
    "    all_candidates = {}\n",
    "    for query, query_df in df.groupby('query_id'):\n",
    "        positive_candidates[query] = query_df[query_df['score'] == 1]['cand_id'].tolist()\n",
    "        all_candidates[query] = query_df['cand_id'].tolist()\n",
    "    return positive_candidates, all_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a02dc20c-9e7d-4b45-84ae-95ed6a3967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: query_id Value: positive_candidates, all_candidates \n",
    "positive_candidates, all_candidates = get_query_candidates(citation_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53dd39b8-c45b-4369-9193-8e1e4c671a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text of queries. Quert id is the id of the query paper. \n",
    "# Key: query_id Value: query text\n",
    "test_queries_id = citation_prediction['query_id'].unique().tolist()\n",
    "test_queries_text = {}\n",
    "for query_id in test_queries_id:\n",
    "    temp = citation_meta[citation_meta['doc_id']==query_id]\n",
    "    # Some query papers don't have abstract\n",
    "    if temp['abstract'].values:\n",
    "        text = temp['title'].values[0] + temp['abstract'].values[0]\n",
    "    test_queries_text[query_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1283d203-acfe-420e-b366-e214c75815f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_BM25(query, doc_ids):\n",
    "    MAX_SIZE = 5\n",
    "    payload = {\n",
    "                \"bool\": {\n",
    "                  \"must\": [\n",
    "                        {\n",
    "                          \"ids\": {\n",
    "                            \"values\": doc_ids\n",
    "                          }\n",
    "                        }\n",
    "                  ],\n",
    "                  \"should\": [\n",
    "                    {\n",
    "                      \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"abstract\"]\n",
    "                      }\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "    resp = es.search(index=\"scidoc_citation\", query=payload, size=MAX_SIZE)\n",
    "    result = []\n",
    "    # Extract info needed for testing and display. \n",
    "    for item in resp['hits']['hits']:\n",
    "        result.append(item['_id'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3dad258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['86e87db2dab958f1bd5877dc7d5b8105d6e31e46',\n",
       " '632589828c8b9fca2c3a59e97451fde8fa7d188d',\n",
       " '22fc3af1fb55d48f3c03cd96f277503e92541c60',\n",
       " '12f107016fd3d062dff88a00d6b0f5f81f00522d',\n",
       " 'c9d41f115eae5e03c5ed45c663d9435cb66ec942']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_BM25(str(test_queries_text['78495383450e02c5fe817e408726134b3084905d']),all_candidates['78495383450e02c5fe817e408726134b3084905d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0f2fdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Direct Search Method to solve Economic Dispatch Problem with Valve-Point EffectScarcity of energy resources, increasing power generation cost and ever-growing demand for electric energy necessitates optimal economic dispatch in today’s power systems. The main objective of economic dispatch is to reduce the total power generation cost, while satisfying various equality and inequality constraints. Traditionally in economic dispatch problems, the cost function for generating units has been approximated as a quadratic function which doesn’t provide accurate results. Moreover, to obtain accurate fuel cost, valve-point effect in thermal power plant has to be taken into account. The inclusion of valve-point effect makes the modeling of the fuel cost functions of generating units more practical. In this paper a new evolutionary algorithm called Pattern Search Technique, has been employed to solve economic dispatch problem with the valve-point effect. Using this technique the non-linear cost function is solved for three unit system and the results are compared with the traditional PSO and GA method. These results prove that Pattern Search method is capable of getting higher quality solution including mathematical simplicity, fast convergence, and robustness to solve hard optimization problems.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries_text['78495383450e02c5fe817e408726134b3084905d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad6650d5-2393-426f-a5d5-f173af35d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(relevant_docs, retrieval_results):\n",
    "    \"\"\"\n",
    "    Calculates the mean average precision (MAP) given a list of relevant documents\n",
    "    and a list of retrieval results.\n",
    "    \n",
    "    Inputs:\n",
    "    relevant_docs: A list of lists, where each inner list contains the relevant\n",
    "                          document IDs for a query.\n",
    "    retrieval_results: A list of lists, where each inner list contains the\n",
    "                              document IDs retrieved by a model for a query.\n",
    "    \n",
    "    return: The mean average precision (MAP).\n",
    "    \"\"\"\n",
    "    average_precision = 0\n",
    "    num_queries = len(relevant_docs)\n",
    "    \n",
    "    for i in range(num_queries):\n",
    "        query_rel_docs = relevant_docs[i]\n",
    "        query_ret_results = retrieval_results[i]\n",
    "        \n",
    "        precision_at_k = []\n",
    "        num_rel_docs = 0\n",
    "        \n",
    "        for k in range(len(query_ret_results)):\n",
    "            if query_ret_results[k] in query_rel_docs:\n",
    "                num_rel_docs += 1\n",
    "                precision_at_k.append(num_rel_docs / (k + 1))\n",
    "        \n",
    "        if len(precision_at_k) > 0:\n",
    "            average_precision += sum(precision_at_k) / len(precision_at_k)\n",
    "    \n",
    "    mean_average_precision = average_precision / num_queries\n",
    "    return mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "898f7d51-7619-49b1-9d75-38f7c2c5d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(test_queries, positive_candidates, all_candidates):\n",
    "    retrieval_results = []\n",
    "    relevant_docs = []\n",
    "    for query_id, query_text in test_queries.items():\n",
    "        retrieved = search_BM25(query_text, all_candidates[query_id])\n",
    "        retrieval_results.append(retrieved)\n",
    "        relevant_docs.append(positive_candidates[query_id])\n",
    "    score = calculate_map(relevant_docs, retrieval_results)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9148ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 MAP score is:  0.9156875000000022\n",
      "Total time used is  32.19122672080994\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "BM25_score = final_result(test_queries_text, positive_candidates, all_candidates)\n",
    "end = time.time()\n",
    "print(\"BM25 MAP score is: \", BM25_score)\n",
    "print(\"Total time used is \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df7347",
   "metadata": {},
   "source": [
    "### Re-rank with harmonic centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c89874c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def calculate_harmonic_centralities(all_candidates, candidates_edges_dict):\n",
    "    result = []\n",
    "    for query_id, candidates in all_candidates.items():\n",
    "        start = time.time()\n",
    "        nodes = candidates\n",
    "        edges = candidates_edges_dict[query_id]\n",
    "        \n",
    "        # Create a graph from the list of edges\n",
    "        G = nx.Graph(edges)\n",
    "    \n",
    "        # Calculate harmonic centralities for each node in the input node list\n",
    "        harmonic_centralities = nx.harmonic_centrality(G, nodes)\n",
    "        result.append(harmonic_centralities)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(query_id, \" done in {}.\\n\".format(end - start))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e65134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Calculate candidates_edges_dict\n",
    "# candidates_edges_dict = {}\n",
    "# i = 0\n",
    "# for query_id, candidates in all_candidates.items():\n",
    "#     edges = []\n",
    "#     for candidate in candidates:\n",
    "#         temp = citation_meta[citation_meta['doc_id'] == candidate]\n",
    "#         citations = temp['cited_by'].values[0]\n",
    "#         references = temp['references'].values[0]\n",
    "#         for paper in citations:\n",
    "#             if paper in candidates:\n",
    "#                 edges.append((paper, candidate))\n",
    "        \n",
    "#         for paper in references:\n",
    "#             if paper in candidates:\n",
    "#                 edges.append((candidate, paper))\n",
    "#     candidates_edges_dict[query_id] = edges\n",
    "#     print(i, ' done.')\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f391a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A new version of candidates_edges_dict\n",
    "## It doesn't exclude edges with nodes which are not candidate papers. \n",
    "candidates_edges_dict_no_exclusion = {}\n",
    "for query_id, candidates in all_candidates.items():\n",
    "    edges = []\n",
    "    for candidate in candidates:\n",
    "        temp = citation_meta[citation_meta['doc_id'] == candidate]\n",
    "        citations = temp['cited_by'].values[0]\n",
    "        references = temp['references'].values[0]\n",
    "        for paper in citations:\n",
    "                edges.append((paper, candidate))\n",
    "        \n",
    "        for paper in references:\n",
    "                edges.append((candidate, paper))\n",
    "    candidates_edges_dict_no_exclusion[query_id] = edges        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "221fdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "candidates_edges_dict_no_exclusion = copy.deepcopy(candidates_edges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "79ed6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonic_centralities = calculate_harmonic_centralities(all_candidates, candidates_edges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calculation here with only one process will take about 49 hours. \n",
    "# Use ten programs to calculate faster and store the results in json files. \n",
    "# Can create a parallel computing program in the future. \n",
    "harmonic_centralities_no_exclusion = calculate_harmonic_centralities(all_candidates, candidates_edges_dict_no_exclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4f7b0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_harmonic_centralities_missed(all_candidates, candidates_edges_dict, query_ids):\n",
    "    result = []        \n",
    "    start = time.time()\n",
    "    for i in [99, 199, 299, 399, 499, 599, 699, 799, 899, 999]:\n",
    "        query_id = query_ids[i]\n",
    "        candidates = all_candidates[query_id]\n",
    "        nodes = candidates\n",
    "        edges = candidates_edges_dict[query_id]\n",
    "\n",
    "        # Create a graph from the list of edges\n",
    "        G = nx.Graph(edges)\n",
    "\n",
    "        # Calculate harmonic centralities for each node in the input node list\n",
    "        harmonic_centralities = nx.harmonic_centrality(G, nodes)\n",
    "        result.append(harmonic_centralities)\n",
    "\n",
    "        end = time.time()\n",
    "        print(i, \" \", query_id, \" done in {}.\\n\".format(end - start))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4c49bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99   f754cab548f2c209ea7d932084ef768b92b27614  done in 272.2202181816101.\n",
      "\n",
      "199   6a40ffc156aea0c9abbd92294d6b729d2e5d5797  done in 299.5810580253601.\n",
      "\n",
      "299   1b9ce6abc0f3024b88fcd4dbd0c10cf5bcf7d38d  done in 338.6756942272186.\n",
      "\n",
      "399   6affd37b83d4fca0d0e54e5d75433a74cb142671  done in 348.21721029281616.\n",
      "\n",
      "499   57ad8dfb71589360810da83efce67b4cab2ff380  done in 782.3319251537323.\n",
      "\n",
      "599   ce00fc554965ea7b187dfa93292013f019d67d39  done in 783.0188040733337.\n",
      "\n",
      "699   2a8bcf35e6b5b3910eea160b3a1fb3e6bcb3966e  done in 1515.6600120067596.\n",
      "\n",
      "799   3388d516fc26536423b03e1d93a3b62358a6a35f  done in 1597.1662590503693.\n",
      "\n",
      "899   40cdd0de8d05c496ca6658d3d7c45bea028de6be  done in 1597.3775870800018.\n",
      "\n",
      "999   89e58773fa59ef5b57f229832c2a1b3e3efff37e  done in 1605.3648509979248.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_ids = citation_prediction['query_id'].unique()\n",
    "harmonic_centralities_no_exclusion_missed = calculate_harmonic_centralities_missed(all_candidates, candidates_edges_dict, query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "35ef2062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(harmonic_centralities_no_exclusion_missed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9ebc0d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp_centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5cccfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_centralities_no_exclusion = []\n",
    "j = 0\n",
    "for i in range(99, 1099, 100):\n",
    "    file_name = 'harmonic_centralities_no_exclusion_' + str(i) + '.json' \n",
    "        temp_centralities = json.load(f)\n",
    "        harmonic_centralities_no_exclusion += temp_centralities\n",
    "        harmonic_centralities_no_exclusion += [harmonic_centralities_no_exclusion_missed[j]]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "376a16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_18 = json.dumps(harmonic_centralities_no_exclusion)\n",
    "\n",
    "# open file for writing, \"w\" \n",
    "f = open(\"harmonic_centralities_no_exclusion_total.json\",\"w\")\n",
    "\n",
    "# write json object to file\n",
    "f.write(temp_18)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "adcda177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42338.666666721714 1.0\n"
     ]
    }
   ],
   "source": [
    "maximum = 0\n",
    "minimum = 10\n",
    "total = 0\n",
    "for score_dict in harmonic_centralities_no_exclusion:\n",
    "    for key, value in score_dict.items():\n",
    "        if value > maximum:\n",
    "            maximum = value\n",
    "        if value < minimum:\n",
    "            minimum = value\n",
    "        total += value\n",
    "print(maximum, minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "11e35171",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_harmonic_centralities = []\n",
    "for score_dict in harmonic_centralities_no_exclusion:\n",
    "    temp_harmonic = {}\n",
    "    for key, value in score_dict.items():\n",
    "        temp_harmonic[key] = math.log(value + 3 * 10 ** -2)\n",
    "    transformed_harmonic_centralities.append(temp_harmonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "54657344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_BM25_rerank(query, doc_ids):\n",
    "    MAX_SIZE = 30\n",
    "    payload = {\n",
    "                \"bool\": {\n",
    "                  \"must\": [\n",
    "                        {\n",
    "                          \"ids\": {\n",
    "                            \"values\": doc_ids\n",
    "                          }\n",
    "                        }\n",
    "                  ],\n",
    "                  \"should\": [\n",
    "                    {\n",
    "                      \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"abstract\"]\n",
    "                      }\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "    resp = es.search(index=\"scidoc_citation\", query=payload, size=MAX_SIZE)\n",
    "    result = {}\n",
    "    # Extract info needed for testing and display. \n",
    "    for item in resp['hits']['hits']:\n",
    "        result[item['_id']] = item['_score']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "357b4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_harmonic_old(result, harmonic_centralities):\n",
    "    for i in range(len(result)):\n",
    "        papers = result[i]\n",
    "        if harmonic_centralities[i]:\n",
    "            id_score = [('', 0) for _ in range (10)]\n",
    "            for i in range(len(papers)):\n",
    "                doc_id = papers[i]\n",
    "                score = 0\n",
    "#                 print(doc_id)\n",
    "                if doc_id in harmonic_centralities[i]:\n",
    "                    score = harmonic_centralities[i][doc_id]\n",
    "                id_score[i] = (doc_id, score)\n",
    "            id_score = sorted(id_score, key=lambda x: x[1])\n",
    "            result[i] = [id_score[i][0] for i in range(5)] \n",
    "        else:\n",
    "            result[i] = papers[:5]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a67bb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_harmonic(BM25_retrieval_results, harmonic_centralities):\n",
    "    results = []\n",
    "    for alpha in range(1, 10):\n",
    "        alpha /= 10\n",
    "        epoch_result = []\n",
    "        for i in range(len(BM25_retrieval_results)):\n",
    "            doc_id_score_dict = BM25_retrieval_results[i]\n",
    "            id_score = [('', 0) for _ in range (len(doc_id_score_dict))]\n",
    "            for j, (doc_id, BM25_score) in enumerate(doc_id_score_dict.items()):\n",
    "                if doc_id in harmonic_centralities[i]:\n",
    "                    total_score = alpha*harmonic_centralities[i][doc_id]+(1-alpha)*BM25_score\n",
    "                else: \n",
    "                    total_score = (1-alpha) * BM25_score\n",
    "                id_score[j] = (doc_id, total_score)\n",
    "            id_score = sorted(id_score, key=lambda x: x[1], reverse=True)\n",
    "            epoch_result.append([id_score[i][0] for i in range(5)]) \n",
    "        results.append(epoch_result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "875c08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_final_result_old(test_queries, positive_candidates, all_candidates, candidates_edges_dict):\n",
    "        retrieval_results = []\n",
    "        relevant_docs = []\n",
    "        for query_id, query_text in test_queries.items():\n",
    "            retrieved = search_BM25(query_text, all_candidates[query_id])\n",
    "            retrieval_results.append(retrieved)\n",
    "            relevant_docs.append(positive_candidates[query_id])\n",
    "        harmonic_centralities = calculate_harmonic_centralities(all_candidates, candidates_edges_dict)\n",
    "        print(len(retrieval_results), len(harmonic_centralities))\n",
    "        retrieval_results = rerank_harmonic(retrieval_results, harmonic_centralities)\n",
    "        score = calculate_map(relevant_docs, retrieval_results)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "85a1a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_final_result(test_queries, positive_candidates, all_candidates, transformed_harmonic_centralities):\n",
    "    retrieval_results = []\n",
    "    relevant_docs = []\n",
    "    scores = []\n",
    "    for query_id, query_text in test_queries.items():\n",
    "        retrieved = search_BM25_rerank(query_text, all_candidates[query_id])\n",
    "        retrieval_results.append(retrieved)\n",
    "        relevant_docs.append(positive_candidates[query_id])\n",
    "    retrieval_results = rerank_harmonic(retrieval_results, transformed_harmonic_centralities)\n",
    "    for retrieval_result in retrieval_results:\n",
    "        score = calculate_map(relevant_docs, retrieval_result)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "33efb2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used is  27.18969702720642\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rerank_result = rerank_final_result(test_queries_text, positive_candidates, all_candidates, transformed_harmonic_centralities)\n",
    "end = time.time()\n",
    "# print(\"Re-ranking model MAP score is: \", rerank_result)\n",
    "print(\"Total time used is \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "07d8d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9154138888888909,\n",
       " 0.9170083333333354,\n",
       " 0.9209361111111131,\n",
       " 0.9252500000000018,\n",
       " 0.9290361111111127,\n",
       " 0.9321513888888914,\n",
       " 0.9381888888888915,\n",
       " 0.9457680555555578,\n",
       " 0.9589555555555578]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
